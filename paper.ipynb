{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи, цели работы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цель работы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель этой лабораторной работы - изучить и применить готовые библиотеки для оптимизации на Python, в частности, PyTorch и различные методы оптимизации из SciPy. Также, требуется сравнить эффективность работы этих методов с нашими реализациями из прошлых работ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для достижения указанной цели\n",
    "\n",
    "1. Изучить использование вариантов SGD (torch.optim) из PyTorch. Исследовать их эффективность и сравнить с собственными реализациями из предыдущих работ.\n",
    "2. Изучить использование готовых методов оптимизации из SciPy (scipy.optimize.minimize, scipy.optimize.least_squares). Исследовать их эффективность и сравнить с собственными реализациями из предыдущих работ.\n",
    "3. Реализовать использование PyTorch для вычисления градиента и сравнить его с другими подходами.\n",
    "4. Исследовать, как задание границ изменения параметров влияет на работу методов из SciPy.\n",
    "5. Исследовать использование линейных и нелинейных ограничений при использовании scipy.optimize.minimize из SciPy. Рассмотреть случаи, когда минимум находится на границе заданной области и когда он расположен внутри.\n",
    "6. Подготовить отчет, содержащий описание реализованных алгоритмов, реализацию, необходимые тесты и таблицы. Отчет должен также включать анализ результатов, преимуществ и ограничений методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ход работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка среды, определение полезных функций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В предыдущих сериях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import profiler\n",
    "import descent\n",
    "import regression\n",
    "import visualization\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "np.set_printoptions(precision=2, suppress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве задачи Least Squares мы будем использовать модель нелинейной регрессии из прошлой работы на базе датасета изменения погоды от Яндекса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.get_data()\n",
    "data_weather = dataset.get_data_weather()\n",
    "visualization.visualize_regression([0.0], *data_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, данные вполне периодичны. Попробуем их описать синусом:\n",
    "\n",
    "Определим модель как\n",
    "$$M(x, W) = W_1 + W_2 \\cdot x + W_3 \\cdot x^2 + W_4 \\cdot x^3 + W_5 \\cdot \\sin (x \\cdot W_6 + W_7)$$\n",
    "Тогда Loss-функция будет выглядеть как\n",
    "$$\n",
    "f(W) = \\sum_{i\\in{DATA_x}} (DATA_{yi} - M(i))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_weather, f_weather_chunk = dataset.get_nonlinear_loss_func(*data_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве квадратичной задачи для градиентного спуска, будем использовать Loss-функцию линейной регрессии из работы №2. Она построена на базе датасета успеваемости студентов в зависимости от количества часов подготовки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_stud, f_stud_chunk = dataset.get_linear_loss_func(*data)\n",
    "visualization.visualize_regression([0.0], *data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rosenbrock function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Она пригодится для сравнения работы различных алгоритмов оптимизации\n",
    "\n",
    "Определим её следующим образом:\n",
    "$$\n",
    "f(x, y) = (1 - x)^2 + 100(y - x^2)^2\n",
    "$$\n",
    "Это нелинейная функция, будем использовать её минимизировать для демонстрации работы некоторых методов в будущем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Исследование реализации SGD из Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В прошлых работах были реализованы методы:\n",
    "- Sgd\n",
    "- Sgd with momentum\n",
    "- Rmsprop\n",
    "- Adagrad\n",
    "- Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descent import (\n",
    "    minibatch_descent,\n",
    "    nesterov_minibatch_descent,\n",
    "    rmsprop_minibatch_descent,\n",
    "    adagrad_minibatch_descent,\n",
    "    adam_minibatch_descent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция Розенброка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наша реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import squared, f_rosenbrock, f_rosenbrock_chunk\n",
    "\n",
    "print(\"Глобальный минимум: [1.0, 1.0]\")\n",
    "visualization.visualize_multiple_descent_2args(\n",
    "    {\n",
    "        \"Adam\": adam_minibatch_descent(\n",
    "            f=squared(f_rosenbrock_chunk()),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            decay=descent.step_decay(1.0, 0.8, 100),\n",
    "            n_epochs=1000,\n",
    "            tol=0.01,\n",
    "            betta1=0.9,\n",
    "            betta2=0.9,\n",
    "        ),\n",
    "        \"SGD\": minibatch_descent(\n",
    "            f=squared(f_rosenbrock_chunk()),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.constant_lr_decay(0.00001),\n",
    "            n_epochs=1000,\n",
    "            tol=0.01,\n",
    "        ),\n",
    "        \"Nesterov\": nesterov_minibatch_descent(\n",
    "            f=squared(f_rosenbrock_chunk()),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.constant_lr_decay(0.0001),\n",
    "            n_epochs=1000,\n",
    "            tol=0.01,\n",
    "            alpha=0.9,\n",
    "        ),\n",
    "        \"RMSProp\": rmsprop_minibatch_descent(\n",
    "            f=squared(f_rosenbrock_chunk()),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.step_decay(1.0, 0.5, 100),\n",
    "            n_epochs=1000,\n",
    "            tol=0.01,\n",
    "            alpha=0.9,\n",
    "        ),\n",
    "        \"Adagrad\": adagrad_minibatch_descent(\n",
    "            f=squared(f_rosenbrock_chunk()),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.constant_lr_decay(1.0),\n",
    "            n_epochs=1000,\n",
    "            tol=0.01,\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    "    print_points=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим аналогичные методы в реализации PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import descent\n",
    "\n",
    "visualization.visualize_multiple_descent_2args(\n",
    "    {\n",
    "        \"Adam\": descent.torch_descent(\n",
    "            torch.optim.Adam(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=1.0,\n",
    "                betas=(0.9, 0.9),\n",
    "            ),\n",
    "            f_rosenbrock,\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            100,  # Step size\n",
    "            0.8,  # Gamma\n",
    "        ),\n",
    "        \"SGD\": descent.torch_descent(\n",
    "            torch.optim.SGD(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=0.00001,\n",
    "            ),\n",
    "            f_rosenbrock,\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"Nesterov\": descent.torch_descent(\n",
    "            torch.optim.SGD(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=0.0001,\n",
    "                momentum=0.1,\n",
    "                nesterov=True,\n",
    "            ),\n",
    "            f_rosenbrock,\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"RMSProp\": descent.torch_descent(\n",
    "            torch.optim.RMSprop(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=1.0,\n",
    "                alpha=0.9,\n",
    "            ),\n",
    "            f_rosenbrock,\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            100,  # Step size\n",
    "            0.5,  # Gamma\n",
    "        ),\n",
    "        \"Adagrad\": descent.torch_descent(\n",
    "            torch.optim.Adagrad(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=1.0,\n",
    "            ),\n",
    "            f_rosenbrock,\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ввиду обусловленности представленной функции, обычный стохастический спуск так и не удалось адекватно стабилизировать, он начал сходиться только при чрезвычайно маленьком Learning Rate (1e-5). Каждое его улучшение помогает улучшить и ускорить сходимость, что отлично видно на графиках, учитывая подобранный Learning Rate для каждого из методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наша реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import squared\n",
    "import time\n",
    "\n",
    "calc_start = time.time()\n",
    "visualization.linear_multiple_demo_2args(\n",
    "    {\n",
    "        \"Adam\": adam_minibatch_descent(\n",
    "            f=squared(f_stud_chunk),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            decay=descent.constant_lr_decay(1e-3),\n",
    "            n_epochs=1000,\n",
    "            tol=1e-7,\n",
    "            betta1=0.9,\n",
    "            betta2=0.999,\n",
    "            batch_size=2,\n",
    "        ),\n",
    "        \"Nesterov\": nesterov_minibatch_descent(\n",
    "            f=squared(f_stud_chunk),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.step_decay(0.01, 0.5, 10),\n",
    "            n_epochs=1000,\n",
    "            tol=1e-7,\n",
    "            alpha=0.35,\n",
    "            batch_size=2,\n",
    "        ),\n",
    "        \"RMSProp\": rmsprop_minibatch_descent(\n",
    "            f=squared(f_stud_chunk),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.constant_lr_decay(0.01),\n",
    "            n_epochs=1000,\n",
    "            tol=1e-7,\n",
    "            alpha=0.99,\n",
    "            batch_size=2,\n",
    "        ),\n",
    "        \"Adagrad\": adagrad_minibatch_descent(\n",
    "            f=squared(f_stud_chunk),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.constant_lr_decay(1.0),\n",
    "            n_epochs=1000,\n",
    "            tol=1e-7,\n",
    "            batch_size=2,\n",
    "        ),\n",
    "        \"SGD\": minibatch_descent(\n",
    "            f=squared(f_stud_chunk),\n",
    "            df=descent.numeric_gradient,\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            lr=descent.step_decay(0.01, 0.5, 10),\n",
    "            n_epochs=1000,\n",
    "            tol=1e-7,\n",
    "            batch_size=2,\n",
    "        ),\n",
    "    },\n",
    "    f_stud,\n",
    "    *data\n",
    ")\n",
    "print(\"Elapsed: \", time.time() - calc_start, \"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PyTorch существуют абстракции для построения лосс-функций из датасетов. Так, мы можем воспользоваться `torch.util.data.DataSet` для представления нашего датасета \"про студентов\" в формате PyTorch.\n",
    "\n",
    "Далее, мы можем воспользоваться `torch.util.data.DataLoader` для разбиения нашего датасета на батчи, из которых, в свою очередь, мы будем формировать Loss-функцию на каждой итерации в процессе оптимизации.\n",
    "\n",
    "Так, мы сделаем наш `torch.optim.SGD` по-настоящему SGD. Как ни странно, в самой реализации от PyTorch у SGD нет ничего стохастического и разбиение функции на батчи - это целиком наша задача."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import torch_loss\n",
    "from torch.utils.data import DataLoader\n",
    "import dataset\n",
    "\n",
    "y = torch.tensor(data[1], dtype=torch.float)\n",
    "x = torch.tensor(data[0], dtype=torch.float)\n",
    "data_set = dataset.TorchDataset(x, y)\n",
    "\n",
    "torch_loss(x, y)(\n",
    "    torch.tensor([3.247829835435748, 5.313336982957038])\n",
    ")  # Eventually, data_set will be consumed by DataLoader\n",
    "# that will be able to split it into batches in the same \"x, y\" format that can be consumed by \"torch_loss\" loss-function factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_start = time.time()\n",
    "visualization.linear_multiple_demo_2args(\n",
    "    {\n",
    "        \"Adam\": descent.torch_descent_stochastic(\n",
    "            torch.optim.Adam(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=1e-3,\n",
    "                betas=(0.9, 0.999),\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set, batch_size=2),\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"Nesterov\": descent.torch_descent_stochastic(\n",
    "            torch.optim.SGD(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=0.01,\n",
    "                nesterov=True,\n",
    "                momentum=1 - 0.35,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set, batch_size=2),\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            10,  # Step size\n",
    "            0.5,  # Gamma\n",
    "        ),\n",
    "        \"RMSProp\": descent.torch_descent_stochastic(\n",
    "            torch.optim.RMSprop(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=0.01,\n",
    "                alpha=0.99,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set, batch_size=2),\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"Adagrad\": descent.torch_descent_stochastic(\n",
    "            torch.optim.Adagrad(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=1.0,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set, batch_size=2),\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"SGD\": descent.torch_descent_stochastic(\n",
    "            torch.optim.SGD(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True)],\n",
    "                lr=0.01,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set, batch_size=2),\n",
    "            1000,\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            10,  # Step size\n",
    "            0.5,  # Gamma\n",
    "        ),\n",
    "    },\n",
    "    f_stud,\n",
    "    *data\n",
    ")\n",
    "print(\"Elapsed: \", time.time() - calc_start, \"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, судя по графикам, результаты работы алгоритмов чрезвычайно похожи. Однако, реализация PyTorch работала всего 43.563 секунды против 73.169 у нашей реализации.\n",
    "\n",
    "Ускорение в 1.68 раза, более точное вычисление производных благодаря дуальным числам - это ещё не всё, что может дать нам PyTorch. Покажем его истинную силу:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да-да, настоящая сила PyTorch сокрыта в возможности отправить вычисления прямо на нашу видеокарту. Добиться этого нетрудно, достаточно\n",
    "правильно скомпилировать библиотеку, установить нужные CUDA рантаймы, иметь поддерживаемую карту, а так же проинициализировать всё правильно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что `cuda.is_available() == True`, а значит, мы можем двигаться дальше. Осталось просто добавить нашим тензорам параметр `device=cuda` и \"дело в шляпе\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device(\"cuda:0\")\n",
    "torch.cuda.get_device_name(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cuda = x.to(cuda)\n",
    "y_cuda = y.to(cuda)\n",
    "data_set_cuda = dataset.TorchDataset(x_cuda, y_cuda)\n",
    "\n",
    "torch_loss(x_cuda, y_cuda)(\n",
    "    torch.tensor([3.247829835435748, 5.313336982957038], device=cuda)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "calc_start = time.time()\n",
    "visualization.linear_multiple_demo_2args(\n",
    "    {\n",
    "        \"Adam\": descent.torch_descent_stochastic(\n",
    "            torch.optim.Adam(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True, device=cuda)],\n",
    "                lr=5e-2,\n",
    "                betas=(0.9, 0.999),\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set_cuda, batch_size=100),\n",
    "            10000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"Nesterov\": descent.torch_descent_stochastic(\n",
    "            torch.optim.SGD(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True, device=cuda)],\n",
    "                lr=0.01,\n",
    "                nesterov=True,\n",
    "                momentum=1 - 0.35,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set_cuda, batch_size=100),\n",
    "            10000,\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            500,  # Step size\n",
    "            0.5,  # Gamma\n",
    "        ),\n",
    "        \"RMSProp\": descent.torch_descent_stochastic(\n",
    "            torch.optim.RMSprop(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True, device=cuda)],\n",
    "                lr=0.01,\n",
    "                alpha=0.99,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set_cuda, batch_size=100),\n",
    "            10000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"Adagrad\": descent.torch_descent_stochastic(\n",
    "            torch.optim.Adagrad(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True, device=cuda)],\n",
    "                lr=1.0,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set_cuda, batch_size=100),\n",
    "            10000,\n",
    "            torch.optim.lr_scheduler.ConstantLR,\n",
    "        ),\n",
    "        \"SGD\": descent.torch_descent_stochastic(\n",
    "            torch.optim.SGD(\n",
    "                [torch.tensor([-10.0, -10.0], requires_grad=True, device=cuda)],\n",
    "                lr=0.01,\n",
    "            ),\n",
    "            torch_loss,\n",
    "            DataLoader(dataset=data_set_cuda, batch_size=100),\n",
    "            10000,\n",
    "            torch.optim.lr_scheduler.StepLR,\n",
    "            500,  # Step size\n",
    "            0.5,  # Gamma\n",
    "        ),\n",
    "    },\n",
    "    f_stud,\n",
    "    *data\n",
    ")\n",
    "print(\"Elapsed: \", time.time() - calc_start, \"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, на предыдущих демонстрациях мы делали epoch*(dataset_size/batch_size)=1000*(100/2)=50000 итераций стохастического спуска.\n",
    "\n",
    "Теперь мы смогли перенести вычисления на GPU, благодаря чему мы можем значительно снизить стоимость увеличения batch_size.\n",
    "То есть теперь мы можем делать не стохастический спуск одновременно по всему датасету, что позволяет значительно повысить точность спуска и, следовательно, увеличить learing_rate и уменьшить число epoch\n",
    "А так же, мы можем бесплатно увеличивать размер датасета, что не повлияет ни на скорость спуска, так как итерации вычисления градиента по всему батчу распараллелены на CUDA ядрах.\n",
    "Это может продолжаться пока у нас хватает вычислителей и видеопамяти для таких манипуляций. То есть теперь batch_size выгодно выставить именно такого размера, какой видеокарта может эффективно распараллелить (в нашем случае датасет имеет размер всего 100, а значит batch_size будет равен размеру датасета).\n",
    "\n",
    "\n",
    "Увеличим epoch в 50 раз, получим 50000*(100/100)=50000 итераций НЕСТОХАСТИЧЕСКОГО спуска. Точность гораздо выше, а время вычислений всего 5 минут (в 5 раз выше однопоточных вычислений на процессоре, при том, что мы увеличили стоимость каждого шага в 50 раз за счёт увеличения batch_size).\n",
    "\n",
    "Теперь воспользуемся преимуществом в точности спуска и уменьшим число epoch в 5 раз (теперь имеем 10000*(100/100)=10000 итераций). Все алгоритмы сошлись идеально в одной точке минимума точнее, чем за 50000 итераций на процессоре (так как спуск более не стохастический всё же), но при этом время вычисления вообще не изменилось: имеем всё те же 60 секунд, что и раньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения задания было проведено сравнение собственной реализации методов оптимизации на Python и реализации этих же методов в библиотеке PyTorch. Были рассмотрены следующие методы: SGD, Nesterov, RMSprop, Adagrad и Adam.\n",
    "\n",
    "Согласно полученным результатам, обе реализации показывают схожие результаты в плане сходимости алгоритмов. Однако, реализация PyTorch показала значительное преимущество в скорости работы - она была быстрее на 68%, что является важным фактором при работе с большими объемами данных.\n",
    "\n",
    "Более того, PyTorch предоставляет возможность использования вычислительных ресурсов графического процессора (GPU), что позволяет еще больше ускорить процесс оптимизации. Это особенно актуально при работе с большими объемами данных и когда возможно использование больших размеров батчей.\n",
    "\n",
    "Так, при использовании GPU, время вычислений сократилось до 5 минут при увеличении количества эпох в 50 раз, что в 5 раз быстрее, чем однопоточные вычисления на процессоре. При этом, точность спуска значительно возросла благодаря использованию нестохастического спуска.\n",
    "\n",
    "Вывод: использование готовых реализаций методов оптимизации из библиотеки PyTorch позволяет значительно ускорить процесс оптимизации, увеличить его точность и эффективно использовать ресурсы графического процессора. Это делает PyTorch предпочтительным выбором для работы с большими объемами данных и сложными моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Задание 2. Исследование методов оптимизации SciPy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение с прошлой работой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import descent\n",
    "import bfgs\n",
    "\n",
    "reload(descent)\n",
    "reload(visualization)\n",
    "\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"bfgs\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"bfgs\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"dogleg\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"dogleg\",\n",
    "            tol=1e-6,\n",
    "            jac=descent.get_jac(f_rosenbrock),\n",
    "            hess=descent.get_hess(f_rosenbrock),\n",
    "        ),\n",
    "        \"newton\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"newton-cg\",\n",
    "            tol=1e-6,\n",
    "            jac=descent.get_jac(f_rosenbrock),\n",
    "        ),\n",
    "        \"dogleg ours\": lambda: descent.powell_dog_leg(\n",
    "            x0=np.array([-10.0, -10.0]),\n",
    "            rsl=f_rosenbrock_chunk(),\n",
    "            grad=descent.numeric_gradient,\n",
    "        ),\n",
    "        \"bfgs ours\": lambda: bfgs.bfgs(\n",
    "            f_rosenbrock,\n",
    "            descent.numeric_gradient,\n",
    "            x_0=np.array((-1.0, -1.0)),\n",
    "            epochs=1000,\n",
    "        ),\n",
    "        \"l-bfgs ours\": lambda: bfgs.l_bfgs(\n",
    "            f_rosenbrock,\n",
    "            descent.numeric_gradient,\n",
    "            x_0=np.array((-10.0, -10.0)),\n",
    "            epochs=1000,\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    "    visualization_area=((-13, 12), (-20, 130)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все методы, как встроенные, так и самописные, успешно сходятся к минимуму функции Розенброка.\n",
    "\n",
    "* Время работы встроенных функций оптимизации в общем больше, чем время работы самописных реализаций. Это может объясняться тем, что встроенные функции содержат дополнительные проверки, что приводит к дополнительному времени выполнения.\n",
    "\n",
    "* Все самописные функции показали более эффективное использование памяти по сравнению с встроенными функциями. Это опять-таки может объясняться меньшим количеством дополнительных проверок и функций в самописных реализациях.\n",
    "\n",
    "* Встроенные функции требуют больше точек для сходимости.\n",
    "\n",
    "Таким образом, эти результаты показывают, что, хотя самописные функции оптимизации могут быть более эффективными с точки зрения времени выполнения и использования памяти, встроенные функции оптимизации могут быть более универсальными, что делает их более подходящими для общего использования. Однако, в определенных ситуациях и с учетом определенных требований, самописные функции могут оказаться предпочтительнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import descent\n",
    "import bfgs\n",
    "\n",
    "reload(descent)\n",
    "reload(bfgs)\n",
    "reload(visualization)\n",
    "\n",
    "f, f_chunk = dataset.get_linear_loss_func(*data)\n",
    "x0 = np.array([-30.0, -30.0])\n",
    "visualization.linear_multiple_demo_2args_wh_time(\n",
    "    {\n",
    "        \"bfgs\": lambda: descent.scipy_descent(\n",
    "            f, x0, method=\"bfgs\", tol=1e-6, jac=\"2-point\"\n",
    "        ),\n",
    "        \"dogleg\": lambda: descent.scipy_descent(\n",
    "            f,\n",
    "            x0,\n",
    "            method=\"dogleg\",\n",
    "            tol=1e-6,\n",
    "            jac=descent.get_jac(f),\n",
    "            hess=descent.get_hess(f),\n",
    "        ),\n",
    "        \"dogleg ours\": lambda: descent.powell_dog_leg(\n",
    "            x0=x0, rsl=f_chunk, grad=descent.numeric_gradient\n",
    "        ),\n",
    "        \"bfgs ours\": lambda: bfgs.bfgs(\n",
    "            f, descent.numeric_gradient, x_0=x0, epochs=10\n",
    "        ),        \n",
    "        \"gauss_newton ours\": lambda: descent.gauss_newton_descent(\n",
    "            x0=x0, rsl=f_chunk, grad=descent.numeric_gradient\n",
    "        ),\n",
    "\n",
    "    },\n",
    "    f,\n",
    "    *data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление градиента с помощью PyTorch, сравнение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. bfgs vs bfgs ours: Встроенная реализация метода BFGS сходится, используя большее количество точек, чем собственная реализация.\n",
    "2. dogleg vs dogleg ours: Встроенная реализация метода Dogleg сходится с использованием меньшего количества точек по сравнению с собственной реализацией, но время работы встроенной реализации значительно выше. Это может быть связано с более сложной и универсальной реализацией встроенного метода. С точки зрения использования памяти, наша реализация оказывается более эффективной.\n",
    "\n",
    "Таким образом, собственные реализации методов показывают хорошую производительность, но имеют некоторые недостатки по сравнению с встроенными функциями из библиотеки scipy. Это связано в первую очередь с тем, что scipy оптимизирован для работы с большим спектром задач, а наши реализации были ориентированы на конкретные случаи использования. Поэтому стоит учесть, что в более общих сценариях использования встроенные функции могут показывать более высокую производительность и надежность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(visualization)\n",
    "visualization_area=((-25, 10),(-30, 150))\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"BFGS\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"bfgs\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"Newton\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"newton-cg\",\n",
    "            tol=1e-6,\n",
    "            jac=descent.get_jac(f_rosenbrock),\n",
    "        ),\n",
    "        \"CG\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"CG\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"Nelder-Mead\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"Nelder-Mead\",\n",
    "            tol=1e-6,\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    "    visualization_area=visualization_area,\n",
    ")\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"BFGS torch\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock_torch,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"bfgs\",\n",
    "            tol=1e-6,\n",
    "            jac=True,\n",
    "        ),\n",
    "        \"Newton torch\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock_torch,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"newton-cg\",\n",
    "            tol=1e-6,\n",
    "            jac=True,\n",
    "        ),\n",
    "        \"CG torch\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock_torch,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"CG\",\n",
    "            tol=1e-6,\n",
    "            jac=True,\n",
    "        ),\n",
    "        \"Nelder-Mead torch\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock_torch,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            method=\"Nelder-Mead\",\n",
    "            tol=1e-6,\n",
    "            jac=True,\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    "    visualization_area=visualization_area,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// :NOTE: pytorch autograd impl\n",
    "// :NOTE: короткй комментарий к графикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. BFGS: Оба метода сходятся к очень близким минимумам, но реализация с использованием PyTorch обеспечивает более точное значение минимума, используя меньше итераций.\n",
    "\n",
    "2. Newton: Оба подхода находят очень близкие минимумы, но Newton torch достигает более точного результата, используя примерно одинаковое количество итераций.\n",
    "\n",
    "3. CG: Аналогично, оба метода достигают очень близких минимумов, но CG torch обеспечивает более точный минимум, используя примерно одинаковое количество итераций.\n",
    "\n",
    "4. Nelder-Mead: Результаты для этих методов идентичны, что логично, поскольку метод Nelder-Mead не использует градиенты.\n",
    "\n",
    "В целом, реализации с автоградиентом работают быстрее, но в при каждом вызове функции нам приходится кастить numpy массив в pytorch тензор, из-за чего время работы увеличивается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение параметров и границ, сравнение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// :NOTE: текст, что происходит, что делаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from funcs import f_rosenbrock\n",
    "\n",
    "bounds1 = scipy.optimize.Bounds(-2, 2)\n",
    "bounds2 = scipy.optimize.Bounds(-5, 5)\n",
    "bounds3 = scipy.optimize.Bounds(-10, 10)\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"bfgs-1\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            bounds=bounds1,\n",
    "            method=\"l-bfgs-b\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"bfgs-2\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            bounds=bounds2,\n",
    "            method=\"l-bfgs-b\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"bfgs-3\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            np.array([-10.0, -10.0]),\n",
    "            bounds=bounds2,\n",
    "            method=\"l-bfgs-b\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from funcs import f_rosenbrock\n",
    "\n",
    "bounds3 = scipy.optimize.Bounds(-200, 200)\n",
    "bounds2 = scipy.optimize.Bounds(-50, 50)\n",
    "bounds1 = scipy.optimize.Bounds(-10, 10)\n",
    "x0 = np.array([-10.0, 10.0])\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"TNC-1\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            bounds=bounds1,\n",
    "            method=\"tnc\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"TNC-2\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            bounds=bounds2,\n",
    "            method=\"tnc\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"TNC-3\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            bounds=bounds3,\n",
    "            method=\"tnc\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(visualization)\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = 3.5 * x + 2.0\n",
    "\n",
    "\n",
    "def residuals(p):\n",
    "    return p[0] * x + p[1] - y\n",
    "\n",
    "\n",
    "bounds1 = Bounds([-5, -5], [5, 5])\n",
    "bounds2 = Bounds([-10, -10], [10, 10])\n",
    "bounds3 = Bounds([-20, -20], [20, 20])\n",
    "x0 = np.array([0.0, 0.0])\n",
    "\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"trust-constr-bounds1\": lambda: descent.scipy_least_squares(\n",
    "            residuals,\n",
    "            x0.copy(),\n",
    "            bounds=bounds1,\n",
    "            ftol=1e-6,\n",
    "        ),\n",
    "        \"trust-constr-bounds2\": lambda: descent.scipy_least_squares(\n",
    "            residuals,\n",
    "            x0.copy(),\n",
    "            bounds=bounds2,\n",
    "            ftol=1e-6,\n",
    "        ),\n",
    "        \"trust-constr-bounds3\": lambda: descent.scipy_least_squares(\n",
    "            residuals,\n",
    "            x0.copy(),\n",
    "            bounds=bounds3,\n",
    "            ftol=1e-6,\n",
    "        ),\n",
    "    },\n",
    "    residuals,\n",
    "    visualize=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, сужение границ ведет к меньшему числу итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бонусное задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Исследование использования ограничений SciPy при работе с scipy.optimize.minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy.optimize.LinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы учимся использовать инструментарий SciPy для оптимизации функции с ограничениями. Для рассмотрения возьмём уже полюбившуюся нам функцию Розенброка. Она имеет минимум в точке $f(1,1) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import f_rosenbrock\n",
    "from visualization import visualize_2arg\n",
    "\n",
    "visualize_2arg(f_rosenbrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда давайте рассмотрим следующие области:\n",
    "\n",
    "1. $\\forall x, y$\n",
    "2. $-100 < x, y < 100$\n",
    "3. $0 < x, y < 2$\n",
    "4. $-10 < x + y < 10$\n",
    "5. $-100 < 100 x - 100 y < 500$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import LinearConstraint\n",
    "from funcs import f_rosenbrock\n",
    "import descent\n",
    "import visualization\n",
    "\n",
    "reload(descent)\n",
    "\n",
    "\n",
    "lin_cons2 = LinearConstraint([[1, 0], [0, 1,]], [-100, -100], [100, 100])\n",
    "lin_cons3 = LinearConstraint([[1, 0], [0, 1,]], [-10, -10], [2, 2])\n",
    "lin_cons4 = LinearConstraint([[1, 1], [0, 0,]], [-10, -10], [0, 0])\n",
    "lin_cons5 = LinearConstraint([[100, -100], [0, 0,]], [-100, -100], [0, 0])\n",
    "\n",
    "x0 = np.array([0.0, 0.0])\n",
    "\n",
    "\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"lin-cons-1\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            #constraints=lin_cons1,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"lin-cons-2\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons2,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"lin-cons-3\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons3,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"lin-cons-4\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons4,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"lin-cons-5\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons5,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        )\n",
    "    },\n",
    "    f_rosenbrock,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть, при правильном выборе ограничений, можно в разы сократить число необходимых шагов для достижения экстремума. И это даже при достаточно скудном инструментарии, ведь задавая линейные ограничения мы можем оперировать только линейными комбинациями координат. Также отметим, что в данном примере минимум лежал внутри рассматриваемых областей. Посмотрим, как ведёт себя метод при задаче ограничений, когда минимум находится на границе (или вне)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import LinearConstraint\n",
    "from funcs import f_rosenbrock\n",
    "import descent\n",
    "import visualization\n",
    "\n",
    "reload(descent)\n",
    "reload(visualization)\n",
    "\n",
    "\n",
    "lin_cons2 = LinearConstraint([[1, 0], [0, 1,]], [-100, -100], [0, 0])\n",
    "lin_cons3 = LinearConstraint([[1, 0], [0, 1,]], [10, 10], [np.inf, np.inf])\n",
    "lin_cons4 = LinearConstraint([[1, 0], [0, 1,]], [1, 1], [np.inf, np.inf])\n",
    "lin_cons5 = LinearConstraint([[1, 0], [0, 1,]], [-np.inf, -np.inf], [1, 1])\n",
    "\n",
    "\n",
    "x0 = np.array([0.0, 0.0])\n",
    "\n",
    "\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"lin-cons-2\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons2,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"lin-cons-3\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons3,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"lin-cons-4\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons4,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"lin-cons-5\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=lin_cons5,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        )\n",
    "    },\n",
    "    f_rosenbrock,\n",
    "    visualization_area=((-12, 12),(-12, 100)),\n",
    "    visualization_resolution=1000,\n",
    "    log_trajectory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы пытаемся прийти к минимуму, но останавливаемся на границе области, в приницпе, этого и следовало ожидать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy.optimize.NonlinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем перейти к использованию нелинейных ограничений. Теперь мы не ограничены линейными соотношениями, и можем задавать любую функцию от аргументов, и границы на неё. Посмотрим на набор из цилиндров с вырезанным центром:\n",
    "\n",
    "1. Окружности с центром в $(0, 0)$ и радиусами $0.001 < R^2 < \\infty$\n",
    "2. $0.0001 < R^2 < \\infty$\n",
    "3. $0 < R^2 < 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "from funcs import f_rosenbrock\n",
    "import descent\n",
    "import visualization\n",
    "\n",
    "reload(descent)\n",
    "\n",
    "\n",
    "non_lin1 = NonlinearConstraint(lambda x: x[0] ** 2 + x[1] ** 2, 0.001, np.inf)\n",
    "non_lin2 = NonlinearConstraint(lambda x: x[0] ** 2 + x[1] ** 2, 0.0001, np.inf)\n",
    "non_lin3 = NonlinearConstraint(lambda x: x[0] ** 2 + x[1] ** 2, 0, 2)\n",
    "\n",
    "\n",
    "x0 = np.array([0.0, 0.0])\n",
    "\n",
    "\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"non-lin-cons-1\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=non_lin1,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "    },\n",
    "    f_rosenbrock,\n",
    "    visualization_area=((-12, 12),(-12, 12)),\n",
    "    visualization_resolution=100,\n",
    "    log_trajectory=True,\n",
    ")\n",
    "\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"non-lin-cons-2\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=non_lin2,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"non-lin-cons-3\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=non_lin3,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        )\n",
    "    },\n",
    "    f_rosenbrock,\n",
    "    visualization_area=((-12, 12),(-12, 12)),\n",
    "    visualization_resolution=100,\n",
    "    log_trajectory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем больше кусочек ближе к минимуму мы вырезаем, тем больше итераций становится необходимо для схождения к минимуму (он находится вне рассматриваемой области). Можно попробовать задать более интересные ограничения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "from funcs import f_rosenbrock\n",
    "import descent\n",
    "import visualization\n",
    "\n",
    "reload(descent)\n",
    "\n",
    "\n",
    "non_lin1 = NonlinearConstraint(lambda x: (x[0] - 1) ** 4 - x[1] ** 2 + 1, 0, 10)\n",
    "non_lin2 = NonlinearConstraint(lambda x: np.sin(x[0]) * np.cos(x[1]),0.1, 0.8)\n",
    "\n",
    "x0 = np.array([0.0, 0.0])\n",
    "\n",
    "\n",
    "visualization.visualize_multiple_descent_2args_wh_time(\n",
    "    {\n",
    "        \"non-lin-cons-1\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=non_lin1,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        ),\n",
    "        \"non-lin-cons-2\": lambda: descent.scipy_descent(\n",
    "            f_rosenbrock,\n",
    "            x0.copy(),\n",
    "            constraints=non_lin2,\n",
    "            method=\"SLSQP\",\n",
    "            tol=1e-6,\n",
    "            jac=\"2-point\",\n",
    "        )\n",
    "    },\n",
    "    f_rosenbrock,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть, ограничения необходимо выбирать осознано, учитвая особенности исследуемых функций. При этом, нелинейные ограничения дают большую свободу в выборе ограничения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подытоживая, использование ограничений превносит новые возможности в оптимизации функций, а именно:\n",
    "\n",
    "1. Тонкая настройка различных видов (линейных и нелинейных) даёт возможность ускорить сходимость функции\n",
    "2. Позволяет находить новые локальные минимумы\n",
    "3. При наличии дополнительной информации о задаче может предотвратить случайные блуждания вокруш точки экстремума, что также благоприятно сказывается на скорости сходимости\n",
    "\n",
    "Таким образом,  ограничений является чрезвычайо полезным и нужным инструментом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заключение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
